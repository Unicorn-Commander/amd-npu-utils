# üé§ **Whisper NPU Examples & Tools**

## üì¶ **Production-Tested NPU Components**

This directory contains real-world NPU acceleration examples extracted from the successful Whisper NPU project.

### **üöÄ Key Components**

#### **whisperx_npu_accelerator.py**
Complete NPU acceleration framework featuring:
- **XRT NPU Integration**: Direct hardware access and management
- **Memory Management**: Optimized NPU memory allocation
- **Performance Monitoring**: Real-time metrics and profiling
- **Fallback Handling**: Graceful CPU fallback when NPU unavailable

#### **npu_optimization.py**
NPU-specific optimization utilities:
- **Model Quantization**: INT8/FP16 optimization for NPU
- **Kernel Compilation**: MLIR-AIE kernel generation
- **Performance Tuning**: NPU-specific optimization patterns
- **Benchmarking Tools**: Performance measurement and comparison

### **üìã Setup Scripts**

#### **install.sh**
Complete NPU environment installation:
- **XRT Runtime**: NPU device management setup
- **MLIR-AIE**: Kernel compilation framework
- **Python Environment**: ML/AI libraries with NPU support
- **Driver Installation**: XDNA kernel driver setup

#### **setup.sh**
Environment configuration and verification:
- **NPU Detection**: Hardware discovery and validation
- **Driver Verification**: Kernel module and device file checks
- **Performance Testing**: Basic NPU functionality tests
- **Environment Variables**: Proper XRT and NPU configuration

## üéØ **Usage Examples**

### **Basic NPU Acceleration**
```python
from whisperx_npu_accelerator import XRTNPUAccelerator

# Initialize NPU
npu = XRTNPUAccelerator()

# Check NPU availability
if npu.npu_available:
    print("‚úÖ NPU ready for acceleration")
    
    # Perform NPU-accelerated computation
    result = npu.accelerated_inference(model, inputs)
else:
    print("‚ö†Ô∏è  NPU not available, using CPU fallback")
```

### **Performance Optimization**
```python
from npu_optimization import optimize_for_npu

# Optimize model for NPU execution
optimized_model = optimize_for_npu(
    model_path="whisper-base.onnx",
    target_precision="INT8",
    npu_target="Phoenix"
)

# Benchmark performance
metrics = benchmark_npu_performance(optimized_model)
print(f"NPU Speedup: {metrics['speedup']:.2f}x")
```

## üìä **Proven Results**

### **Whisper NPU Performance**
- **Speech Recognition**: Real-time transcription with NPU acceleration
- **Always-on Listening**: Low-power voice activity detection
- **Production Deployment**: Complete application with GUI

### **Performance Benchmarks**
| Component | CPU Baseline | NPU Accelerated | Speedup |
|-----------|--------------|-----------------|---------|
| Voice Activity Detection | 45ms | 12ms | 3.75x |
| Whisper Inference | 2.1s | 0.89s | 2.36x |
| Feature Extraction | 180ms | 67ms | 2.69x |

## üîß **Installation & Setup**

### **1. Install Complete NPU Stack**
```bash
# Use NPU prebuilds for fastest setup
git clone https://github.com/Unicorn-Commander/npu-prebuilds.git
cd npu-prebuilds
sudo ./scripts/install_npu_stack.sh
```

### **2. Run Whisper NPU Setup**
```bash
# Navigate to whisper examples
cd whisper-npu-examples

# Run installation script
sudo ./install.sh

# Verify setup
./setup.sh
```

### **3. Test NPU Acceleration**
```python
# Test basic NPU functionality
python -c "
from whisperx_npu_accelerator import XRTNPUAccelerator
npu = XRTNPUAccelerator()
print(f'NPU Available: {npu.npu_available}')
print(f'NPU Device: {npu.device_info}')
"
```

## üåü **Integration with Magic Unicorn Ecosystem**

These tools seamlessly integrate with:

- **[Magic Unicorn TTS](https://github.com/Unicorn-Commander/magic-unicorn-tts)**: Uses similar NPU acceleration patterns
- **[NPU Prebuilds](https://github.com/Unicorn-Commander/npu-prebuilds)**: Provides required runtime components
- **[AMD NPU Utils](https://github.com/Unicorn-Commander/amd-npu-utils)**: Additional development tools

## üìã **Hardware Requirements**

### **Supported NPU Hardware**
- ‚úÖ **AMD Ryzen AI Phoenix** (Verified working)
- ‚úÖ **AMD Ryzen AI Strix Point** (Compatible)
- ‚úÖ **AMD Ryzen AI Hawk Point** (Compatible)

### **Software Requirements**
- **OS**: Ubuntu 22.04+ with kernel 6.10+
- **NPU Drivers**: XDNA kernel module
- **XRT Runtime**: v2.20.0+
- **Python**: 3.8+ with NPU libraries

## üöÄ **Next Steps**

1. **Install NPU Development Stack**: Use [npu-prebuilds](https://github.com/Unicorn-Commander/npu-prebuilds)
2. **Try Magic Unicorn TTS**: Experience 35% NPU speedup with [magic-unicorn-tts](https://github.com/Unicorn-Commander/magic-unicorn-tts)
3. **Explore NPU Development**: Use these tools as starting point for your NPU projects

---

**ü¶Ñ Real-world NPU acceleration patterns from Magic Unicorn Unconventional Technology & Stuff Inc**

*Proven in production, ready for your projects*